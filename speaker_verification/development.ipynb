{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arjasc5231/Lingometer/blob/speaker_verification/speaker_verification/development.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PEsKQpkEJVG",
        "outputId": "e69bfa93-4696-4415-c4da-7e52a7a05183"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: import_ipynb in /usr/local/lib/python3.7/dist-packages (0.1.4)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.7/dist-packages (from import_ipynb) (7.9.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from import_ipynb) (5.4.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (2.0.10)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (0.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (4.4.2)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (0.18.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (2.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (5.1.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (57.4.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->IPython->import_ipynb) (0.8.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->import_ipynb) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->import_ipynb) (0.2.5)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat->import_ipynb) (4.11.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->import_ipynb) (4.3.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->import_ipynb) (2.16.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (0.18.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (4.12.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (5.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (4.1.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (22.1.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->import_ipynb) (3.8.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->IPython->import_ipynb) (0.7.0)\n",
            "/content/drive/.shortcut-targets-by-id/1rEYIox5uYM9uP2spDttCYCqtt2GvSbn1/2022 기술 혁신 실험/colab/speaker_verification/code\n",
            "batcher.ipynb\t   eval_metrics.ipynb  network.ipynb\n",
            "constants.ipynb    fitter.ipynb        preprocess.ipynb\n",
            "development.ipynb  loss.ipynb\t       validation.ipynb\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "colab에서만 사용하는 코드\n",
        "\"\"\"\n",
        "\n",
        "# drive mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# import_ipynb module 설치\n",
        "!pip install import_ipynb\n",
        "\n",
        "# 경로이동\n",
        "%cd /content/drive/MyDrive/team_malmungchi/colab/speaker_verification/code\n",
        "!ls"
      ],
      "id": "2PEsKQpkEJVG"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9febc15e",
        "outputId": "df6c2a05-dc66-4aad-e485-93aad95029e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "importing Jupyter notebook from constants.ipynb\n",
            "importing Jupyter notebook from batcher.ipynb\n",
            "importing Jupyter notebook from network.ipynb\n",
            "importing Jupyter notebook from eval_metrics.ipynb\n",
            "importing Jupyter notebook from loss.ipynb\n",
            "importing Jupyter notebook from fitter.ipynb\n",
            "importing Jupyter notebook from validation.ipynb\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import pickle\n",
        "\n",
        "#sys.path.append(\"/content/drive/MyDrive/team_malmungchi/colab/speaker_verification/code\")\n",
        "import import_ipynb\n",
        "from constants import CHECKPOINTS_DIR, NUM_FRAME, NUM_FBANK\n",
        "import batcher\n",
        "import network\n",
        "import loss\n",
        "import fitter\n",
        "from validation import validate\n",
        "\n",
        "tf.config.run_functions_eagerly(True)"
      ],
      "id": "9febc15e"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3dae175d"
      },
      "outputs": [],
      "source": [
        " def train(batcher_name, model_name, loss_name, checkpoint_dir=None, initial_epoch=0, max_epoch=0):\n",
        "    \n",
        "\n",
        "    # Batcher 로드 (train dataset 로드)\n",
        "    Batcher = batcher.get_batcher(batcher_name)\n",
        "    num_speaker= Batcher.num_speaker\n",
        "\n",
        "\n",
        "    # test dataset 로드\n",
        "    test_dataset_path = '../data/validation_batcher/64.npy'  # 일단 임시로 validation과 똑같다.\n",
        "    with open(test_dataset_path,\"rb\") as f: test_X,_ = pickle.load(f)\n",
        "\n",
        "\n",
        "    # optimizer, loss 객체 생성\n",
        "    optimizer = tf.optimizers.Adam(learning_rate=0.001)\n",
        "    Loss = loss.get_loss(loss_name)\n",
        "    \n",
        "    \n",
        "    # 모델 생성\n",
        "    Model = network.get_network(model_name, num_speaker)\n",
        "    Model.summary()\n",
        "    #Model.compile(optimizer='adam', loss=Loss, metrics=['accuracy']) # 이것도 metric이 경우마다 달라질 수 있겠다. fitter 안으로 넣자.\n",
        "    Model.compile(optimizer='adam', loss=Loss) # simMat은 accuracy가 없음\n",
        "\n",
        "\n",
        "    # 체크포인트 경로 생성\n",
        "    if not checkpoint_dir:\n",
        "      checkpoint_dir = f'../model/{model_name}-{batcher_name}-{loss_name}'\n",
        "      if not os.path.exists(checkpoint_dir): os.makedirs(checkpoint_dir)\n",
        "    # 체크포인트 로드\n",
        "    ckpts = os.listdir(checkpoint_dir)\n",
        "    if ckpts:\n",
        "      ckpts.sort(key=lambda x:float(x.split('-')[-1][:-5]))\n",
        "      best_ckpt = ckpts[0]\n",
        "      initial_epoch = int(best_ckpt.split('-')[0])\n",
        "      Model.load_weights(checkpoint_dir+'/'+best_ckpt)\n",
        "      print(f'\\nload exist checkpoint that epoch:{initial_epoch}, EER:'+best_ckpt.split('-')[-1][:-5])\n",
        "    # 체크포인트 객체 생성\n",
        "    checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_dir+'/{epoch:05d}-{val_eer:.4f}.hdf5', monitor='val_eer', mode='min', save_best_only=True)\n",
        "\n",
        "    \n",
        "    # reduce_lr 객체 생성\n",
        "    # reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=10, min_lr=0.0001, verbose=1)\n",
        "\n",
        "\n",
        "    \n",
        "    # train\n",
        "    fitter.fit(Model, Batcher, test_X, loss, initial_epoch, max_epoch, checkpoint)\n",
        "\n",
        "    \n",
        "    # validation\n",
        "    eer = validate(Model)\n",
        "    print(eer)\n",
        "    # eer함수가 단위가 1이 max인듯. (eer=0.13->eer=13%)\n",
        "    \n",
        "    "
      ],
      "id": "3dae175d"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6e6591d",
        "scrolled": true,
        "outputId": "d57306bf-2e26-4b22-eb60-2c0f0a6477ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load exist data\n",
            "Model: \"custom_model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 128, 128, 1)]     0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 126, 126, 32)      320       \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 63, 63, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 61, 61, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 31, 31, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 29, 29, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 15, 15, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 28800)             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 167)               4809767   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,902,439\n",
            "Trainable params: 4,902,439\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "load exist checkpoint that epoch:3, EER:0.3016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/structured_function.py:265: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10\n",
            "10/10 [==============================] - 14s 271ms/step - loss: 33.0420 - val_eer: 0.3141\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 33.8840 - val_eer: 0.3125\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 2s 216ms/step - loss: 39.1829 - val_eer: 0.3648\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 2s 151ms/step - loss: 39.6601 - val_eer: 0.3305\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 1s 135ms/step - loss: 37.7769 - val_eer: 0.3195\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 1s 133ms/step - loss: 37.5286 - val_eer: 0.3328\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 1s 156ms/step - loss: 35.5526 - val_eer: 0.3039\n",
            "0.30390625\n"
          ]
        }
      ],
      "source": [
        "#train('naive_batcher', 'naive_model', 'cross_entropy')\n",
        "\n",
        "#train('simMat_batcher', 'naive_model', 'simMat_loss')\n",
        "\n",
        "train('simMat_online_batcher', 'naive_model', 'simMat_loss', max_epoch=10)"
      ],
      "id": "e6e6591d"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lhi32jd5QWqZ"
      },
      "id": "Lhi32jd5QWqZ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "development.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}