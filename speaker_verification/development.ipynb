{"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/arjasc5231/Lingometer/blob/speaker_verification/speaker_verificaiton/development.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"],"id":"view-in-github"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23261,"status":"ok","timestamp":1662572889490,"user":{"displayName":"이중훈","userId":"12039443064831442063"},"user_tz":-540},"id":"2PEsKQpkEJVG","outputId":"1e2c973a-e568-4448-f352-934150b0a891"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting import_ipynb\n","  Downloading import_ipynb-0.1.4-py3-none-any.whl (4.1 kB)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from import_ipynb) (5.4.0)\n","Requirement already satisfied: IPython in /usr/local/lib/python3.7/dist-packages (from import_ipynb) (7.9.0)\n","Collecting jedi>=0.10\n","  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 33.4 MB/s \n","\u001b[?25hRequirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (0.2.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (57.4.0)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (5.1.1)\n","Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (2.0.10)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (0.7.5)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (2.6.1)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (4.8.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (4.4.2)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->IPython->import_ipynb) (0.8.3)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->import_ipynb) (1.15.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->import_ipynb) (0.2.5)\n","Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->import_ipynb) (2.16.1)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->import_ipynb) (4.3.3)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat->import_ipynb) (4.11.1)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (5.9.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (4.1.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (4.12.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (22.1.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (0.18.1)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->import_ipynb) (3.8.1)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->IPython->import_ipynb) (0.7.0)\n","Installing collected packages: jedi, import-ipynb\n","Successfully installed import-ipynb-0.1.4 jedi-0.18.1\n","/content/drive/.shortcut-targets-by-id/1rEYIox5uYM9uP2spDttCYCqtt2GvSbn1/2022 기술 혁신 실험/colab/speaker_verification/code\n","batcher.ipynb\t   eval_metrics.ipynb  network.ipynb\t utils.ipynb\n","constants.ipynb    fitter.ipynb        preprocess.ipynb\n","development.ipynb  loss.ipynb\t       test_eer.ipynb\n"]}],"source":["\"\"\"\n","# colab에서만 사용하는 코드. import될 때 주석처리 되어있어야 한다.\n","\n","# drive mount. colab에 내 구글 드라이브 연결\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# import_ipynb module 설치\n","!pip install import_ipynb\n","\n","# import를 위한 경로이동\n","%cd /content/drive/MyDrive/team_malmungchi/colab/speaker_verification/code\n","!ls\n","\"\"\""],"id":"2PEsKQpkEJVG"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4677,"status":"ok","timestamp":1662572894158,"user":{"displayName":"이중훈","userId":"12039443064831442063"},"user_tz":-540},"id":"9febc15e","outputId":"f50d0742-920c-4172-d24a-bc571eb671ea"},"outputs":[{"output_type":"stream","name":"stdout","text":["importing Jupyter notebook from constants.ipynb\n","importing Jupyter notebook from batcher.ipynb\n","importing Jupyter notebook from network.ipynb\n","importing Jupyter notebook from eval_metrics.ipynb\n","importing Jupyter notebook from utils.ipynb\n","importing Jupyter notebook from loss.ipynb\n","importing Jupyter notebook from fitter.ipynb\n","importing Jupyter notebook from test_eer.ipynb\n"]}],"source":["import os\n","import sys\n","import tensorflow as tf\n","from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.optimizers import SGD\n","import pickle\n","\n","#sys.path.append(\"/content/drive/MyDrive/team_malmungchi/colab/speaker_verification/code\")\n","import import_ipynb\n","from constants import CHECKPOINTS_DIR, NUM_FRAME, NUM_FBANK\n","import batcher\n","import network\n","import loss\n","import fitter\n","import utils\n","from test_eer import test_frame, test_utt\n","\n","# eager execution 사용. test_step에서 eer 계산에 numpy를 사용하기 때문\n","tf.config.run_functions_eagerly(True)"],"id":"9febc15e"},{"cell_type":"code","execution_count":null,"metadata":{"id":"3dae175d"},"outputs":[],"source":[" def train(model_name, batcher_name, loss_name, train_data_path, initial_epoch=0, max_epoch=0, pre_checkpoint_dir=None, tag=None):\n","    \n","\n","    # Batcher 로드 (train dataset 로드)\n","    Batcher = batcher.get_batcher(batcher_name, train_data_path)\n","\n","\n","    # validation dataset 로드\n","    val_dataset_path = '../data/dataset/val_331_25_128_512.npy'\n","    with open(val_dataset_path,\"rb\") as f: val_X = pickle.load(f)\n","    print('==================================================')\n","    print('load validation dataset')\n","    print('shape of data :', val_X.shape)\n","    \n","\n","    # 모델 생성\n","    Model = network.get_network(model_name)\n","    Model.summary()\n","    print('==================================================')\n","    print(model_name+' is created')\n","\n","\n","    # optimizer 객체 생성\n","    optimizer = tf.optimizers.Adam(learning_rate=0.0001) # 원래는 0.001\n","\n","\n","    # loss 객체 생성\n","    Loss = loss.get_loss(loss_name)\n","\n","\n","    # 체크포인트 경로 생성\n","    print('==================================================')\n","    print('preparing checkpoint...')\n","    checkpoint_dir = f'../model/{model_name}-{batcher_name}-{loss_name}'\n","    if tag: checkpoint_dir+='-'+tag\n","    # transfer learning의 경우 pretrain된 체크포인트 로드\n","    if pre_checkpoint_dir:  \n","      checkpoint_dir += '--transferedFrom--'+pre_checkpoint_dir.split('/')[-1]\n","      best_ckpt = utils.load_best_checkpoint(pre_checkpoint_dir)\n","      Model.load_weights(pre_checkpoint_dir+'/'+best_ckpt)\n","      print('\\nload pre-trainded checkpoint that model:'+pre_checkpoint_dir.split('/')[-1]+f', epoch:{initial_epoch}, EER:'+best_ckpt.split('-')[-1][:-5])\n","    if not os.path.exists(checkpoint_dir): os.makedirs(checkpoint_dir)\n","    # 이전에 학습중이었던 경우 해당 체크포인트 로드해 이어서 학습\n","    best_ckpt = utils.load_best_checkpoint(checkpoint_dir)\n","    if best_ckpt:\n","      initial_epoch = int(best_ckpt.split('-')[0])\n","      Model.load_weights(checkpoint_dir+'/'+best_ckpt)\n","      print('\\nload exist checkpoint that model:'+checkpoint_dir.split('/')[-1]+f', epoch:{initial_epoch}, EER:'+best_ckpt.split('-')[-1][:-5])\n","    # 체크포인트 객체 생성\n","    checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_dir+'/{epoch:05d}-{val_eer:.4f}.hdf5', monitor='val_eer', mode='min', save_best_only=True)\n","\n","\n","    # early_stopping 객체 생성. 30epoch동안 eer이 0.1%도 감소하지 않는다면 중지\n","    early_stopping = EarlyStopping(monitor='val_eer', min_delta=0.001, patience=50, mode='min', verbose=1)\n","\n","    \n","    # reduce_lr 객체 생성. 10epoch동안 val_eer이 감소하지 않는다면 lr 절반으로 줄이기\n","    reduce_lr = ReduceLROnPlateau(monitor='val_eer', factor=0.5, patience=20, mode='min', min_lr=0.000001, verbose=1)\n","\n","    \n","    # train\n","    callbacks = [checkpoint, early_stopping, reduce_lr]\n","    fitter.fit(Model, Batcher, val_X, Loss, initial_epoch, max_epoch, optimizer, callbacks)\n","    print('\\n training is end')\n","\n","\n","    # load best weights\n","    print('==================================================')\n","    print('preparing checkpoint...')\n","    best_ckpt = utils.load_best_checkpoint(checkpoint_dir)\n","    Model.load_weights(checkpoint_dir+'/'+best_ckpt)\n","    best_epoch = int(best_ckpt.split('-')[0])\n","    print(f'load best checkpoint that epoch:{best_epoch}, EER:'+best_ckpt.split('-')[-1][:-5])\n","    del Batcher\n","    del val_X\n","\n","\n","    # test\n","    test_frame(Model)\n","    test_utt(Model)"],"id":"3dae175d"},{"cell_type":"code","execution_count":null,"metadata":{"id":"e6e6591d","scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662573246350,"user_tz":-540,"elapsed":352196,"user":{"displayName":"이중훈","userId":"12039443064831442063"}},"outputId":"21602154-3fd9-4d86-c8a8-1a9d3886a1b7"},"outputs":[{"output_type":"stream","name":"stdout","text":["==================================================\n","[batcher:simMat] load train dataset\n","shape of data : (300, 200, 128, 128, 1)\n","==================================================\n","load validation dataset\n","shape of data : (331, 25, 128, 128, 1)\n","Model: \"custom_model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 128, 128, 1)]     0         \n","                                                                 \n"," conv2d (Conv2D)             (None, 126, 126, 32)      320       \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 63, 63, 32)       0         \n"," )                                                               \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 61, 61, 64)        18496     \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 31, 31, 64)       0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 29, 29, 128)       73856     \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 15, 15, 128)      0         \n"," 2D)                                                             \n","                                                                 \n"," reshape (Reshape)           (None, 15, 1920)          0         \n","                                                                 \n"," bidirectional (Bidirectiona  (None, 256)              2098176   \n"," l)                                                              \n","                                                                 \n"," dense (Dense)               (None, 200)               51400     \n","                                                                 \n","=================================================================\n","Total params: 2,242,248\n","Trainable params: 2,242,248\n","Non-trainable params: 0\n","_________________________________________________________________\n","==================================================\n","CRNN is created\n","==================================================\n","preparing checkpoint...\n","\n","load exist checkpoint that model:CRNN-simMat_batcher-simMat_loss, epoch:1, EER:0.3553\n","==================================================\n","start training...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/structured_function.py:265: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n","  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"]},{"output_type":"stream","name":"stdout","text":["\n"," training is end\n","==================================================\n","preparing checkpoint...\n","load best checkpoint that epoch:1, EER:0.3553\n","============================================\n","start frame level test\n","EER: 0.3585294117647059\n","==================================================\n","start utterence level test\n","EER: 0.35721393034825866\n"]}],"source":["# naive train\n","#train('ACRNN', 'naive_batcher', 'cross_entropy', max_epoch=10)\n","\n","# simMat train\n","# train('CNN', 'simMat_batcher', 'simMat_loss', '../data/dataset/train_300_200_128_512.pickle', max_epoch=100)\n","\n","# transfer\n","# train('naive_model', 'naive_batcher', 'cross_entropy', max_epoch=4)\n","#train('naive_model', 'simMat_batcher', 'simMat_loss', max_epoch=1, pre_checkpoint_dir='../model/naive_model-naive_batcher-cross_entropy')"],"id":"e6e6591d"},{"cell_type":"code","source":[],"metadata":{"id":"Lhi32jd5QWqZ"},"id":"Lhi32jd5QWqZ","execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":5}