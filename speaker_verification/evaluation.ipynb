{"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/arjasc5231/Lingometer/blob/speaker_verification/speaker_verificaiton/development.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"],"id":"view-in-github"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31428,"status":"ok","timestamp":1664443527837,"user":{"displayName":"이중훈","userId":"12039443064831442063"},"user_tz":-540},"id":"2PEsKQpkEJVG","outputId":"938b2753-787b-4be9-cde5-65a80d8cbd13"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting import_ipynb\n","  Downloading import_ipynb-0.1.4-py3-none-any.whl (4.1 kB)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from import_ipynb) (5.4.0)\n","Requirement already satisfied: IPython in /usr/local/lib/python3.7/dist-packages (from import_ipynb) (7.9.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (2.6.1)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (4.8.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (0.7.5)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (0.2.0)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (5.1.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (4.4.2)\n","Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (2.0.10)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (57.4.0)\n","Collecting jedi>=0.10\n","  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 2.1 MB/s \n","\u001b[?25hRequirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->IPython->import_ipynb) (0.8.3)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->import_ipynb) (0.2.5)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->import_ipynb) (1.15.0)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat->import_ipynb) (4.11.1)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->import_ipynb) (4.3.3)\n","Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->import_ipynb) (2.16.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (4.12.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (0.18.1)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (22.1.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (4.1.1)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (5.9.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->import_ipynb) (3.8.1)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->IPython->import_ipynb) (0.7.0)\n","Installing collected packages: jedi, import-ipynb\n","Successfully installed import-ipynb-0.1.4 jedi-0.18.1\n","/content/drive/.shortcut-targets-by-id/1rEYIox5uYM9uP2spDttCYCqtt2GvSbn1/team_malmungchi/colab/speaker_verification/code\n","batcher.ipynb\t\t constants.ipynb     fitter.ipynb      test_eer.ipynb\n","call_development1.ipynb  convert.ipynb\t     loss.ipynb        utils.ipynb\n","call_development2.ipynb  development.ipynb   network.ipynb\n","call_development3.ipynb  eval_metrics.ipynb  preprocess.ipynb\n","call_tflite.ipynb\t evaluation.ipynb    temp.wav\n"]}],"source":["# drive mount. colab에 내 구글 드라이브 연결\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# import_ipynb module 설치\n","!pip install import_ipynb\n","\n","# import를 위한 경로이동\n","%cd /content/drive/MyDrive/team_malmungchi/colab/speaker_verification/code\n","!ls"],"id":"2PEsKQpkEJVG"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7793,"status":"ok","timestamp":1664443535621,"user":{"displayName":"이중훈","userId":"12039443064831442063"},"user_tz":-540},"id":"9febc15e","outputId":"effd98cf-466e-4589-c7dc-d543bb724f2b"},"outputs":[{"name":"stdout","output_type":"stream","text":["importing Jupyter notebook from constants.ipynb\n","importing Jupyter notebook from batcher.ipynb\n","importing Jupyter notebook from network.ipynb\n","importing Jupyter notebook from eval_metrics.ipynb\n","importing Jupyter notebook from utils.ipynb\n","importing Jupyter notebook from loss.ipynb\n","importing Jupyter notebook from fitter.ipynb\n","importing Jupyter notebook from test_eer.ipynb\n"]}],"source":["import os\n","import sys\n","import tensorflow as tf\n","from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.optimizers import SGD\n","import numpy as np\n","import pickle\n","import IPython.display as ipd\n","\n","#sys.path.append(\"/content/drive/MyDrive/team_malmungchi/colab/speaker_verification/code\")\n","import import_ipynb\n","from constants import NUM_FBANK, HOP_LENGTH, NUM_SPEC_PER_SPEAKER, NUM_FRAME, NUM_ENROLL_UTT, NUM_TRUE_UTT, NUM_FALSE_UTT\n","import batcher\n","import network\n","import loss\n","import fitter\n","from utils import load_best_checkpoint, normalize, cosine_similarity\n","from test_eer import test_frame, test_utt\n","from eval_metrics import calculate_eer\n","\n","# eager execution 사용. test_step에서 eer 계산에 numpy를 사용하기 때문\n","tf.config.run_functions_eagerly(True)"],"id":"9febc15e"},{"cell_type":"code","execution_count":null,"metadata":{"id":"e_q8gmOnimzI"},"outputs":[],"source":["import librosa\n","\n","def pcm2npy(file_path):\n","    # https://kaen2891.tistory.com/107\n","    with open(file_path, 'rb') as opened_pcm_file:\n","        buf = opened_pcm_file.read()\n","        pcm = np.frombuffer(buf, dtype = 'int16')\n","        wav = librosa.util.buf_to_float(pcm, 2)\n","    return wav\n","\n","def trim_silence(wav):\n","    energy = np.abs(wav)\n","    silence_threshold = np.percentile(energy, 95)\n","    offsets = np.where(energy > silence_threshold)[0]\n","    # librosa.trim같은 방법도 있음. https://malaya-speech.readthedocs.io/en/latest/remove-silent-vad.html\n","    wav_trimed = wav[offsets[0]:offsets[-1]]\n","    return wav_trimed\n","\n","def npy2spec(wav, sr=44100): # return: [time][freq][ch]\n","    # TODO : 스펙트로그램 파라미터를 아두이노에서 사용할 c++ library와 같게 맞춰야한다.\n","\n","    # sr조심!!!!!!!!!!!!!!!!!\n","    hop = int((HOP_LENGTH/16000)*sr)\n","    spec = librosa.power_to_db(librosa.feature.melspectrogram(y=wav, sr=sr, n_fft=NUM_FBANK, hop_length=hop)) # log mel spectrogram을 생성. n_mels=128이 default값. [freq(128)][time(128)] \n","    \"\"\"\n","    delta1 = librosa.feature.delta(data=mel, width=5)\n","    delta2 = librosa.feature.delta(data=delta1, width=5)\n","    stack = np.dstack((mel,delta1,delta2)) #-> (128,t,3)\n","    \"\"\"\n","    spec = spec.T  # [t][f]\n","    spec_normalized = normalize_frames(spec)  # normalize\n","    spec_normalized = np.expand_dims(spec_normalized, axis=-1) # [time(128)][freq(128)][chnnel(1)]\n","    return spec_normalized\n","\n","def normalize_frames(m, epsilon=1e-12):\n","    return [(v - np.mean(v)) / max(np.std(v), epsilon) for v in m]\n","\n","# 음성 하나를 spectrogram으로 변환\n","def convert(file_path, trim=False):\n","    if file_path[-3:]=='pcm': wav = pcm2npy(file_path); sr=16000\n","    else:\n","      wav,sr = librosa.load(path=file_path)\n","      wav = librosa.resample(wav, sr, 16000) #downsampling\n","      sr = 16000\n","    if trim: wav = trim_silence(wav)\n","    spec = npy2spec(wav, sr)\n","    return spec "],"id":"e_q8gmOnimzI"},{"cell_type":"code","execution_count":null,"metadata":{"id":"3dae175d"},"outputs":[],"source":[" def get_thres(Model):\n","  print('frame level eer')\n","  val_dataset_path = '../data/dataset/test_340_25_128_512.npy'\n","  with open(val_dataset_path,\"rb\") as f: batchs = pickle.load(f)\n","  \n","  num_batch = batchs.shape[0]\n","  BATCH_SIZE = NUM_ENROLL_UTT + NUM_TRUE_UTT + NUM_FALSE_UTT\n","  true_score = []   # true 발화의 점수를 저장할 배열\n","  false_score = []  # false 발화의 점수를 저장할 배열\n","\n","  batchs = np.concatenate(batchs)\n","  pred = Model.predict(batchs)\n","  pred = normalize(pred)\n","  del batchs\n","\n","  for i in range(num_batch):\n","    enroll = pred[i*BATCH_SIZE:i*BATCH_SIZE+NUM_ENROLL_UTT]\n","    enroll = normalize(np.mean(enroll, axis=0)) # 등록 발화를 평균\n","\n","    for j in range(NUM_TRUE_UTT): true_score.append(cosine_similarity(enroll,pred[i*BATCH_SIZE+NUM_ENROLL_UTT+j]))\n","    for j in range(NUM_FALSE_UTT): false_score.append(cosine_similarity(enroll,pred[i*BATCH_SIZE+NUM_ENROLL_UTT+NUM_TRUE_UTT+j]))\n","  \n","  # calculate_eer함수의 인자로 알맞은 형태로 변환. true의 label에 1 표시해주기\n","  scores = np.array(true_score+false_score)\n","  labels = np.array([1.0]*len(true_score)+[0.0]*len(false_score))\n","\n","  # eer 계산\n","  eer,thres = calculate_eer(np.arange(0, 1.0, 0.001), scores, labels, get_threshold=True)\n","  print('EER:', eer)\n","  print('threshold:', thres)\n","\n","\n","  print('utt level eer')\n","  # load data\n","  dataset_path = '../data/dataset/testUtt_201_25.pickle'\n","  with open(dataset_path,\"rb\") as f: batchs = pickle.load(f)\n","  \n","  true_score = []   # true 발화의 점수를 저장할 배열\n","  false_score = []  # false 발화의 점수를 저장할 배열\n","\n","  for batch in batchs:\n","    d_vectors = []\n","    for utt in batch:\n","      specs = split_spec(utt)\n","      pred = Model.predict(specs)\n","      pred = normalize(pred)\n","      d_vector = normalize(np.mean(pred, axis=0))\n","      d_vectors.append(d_vector)\n","    \n","    enroll = d_vectors[:NUM_ENROLL_UTT]\n","    enroll = normalize(np.mean(enroll, axis=0)) # 등록 발화를 평균\n","\n","    for j in range(NUM_TRUE_UTT): true_score.append(cosine_similarity(enroll,d_vectors[NUM_ENROLL_UTT+j]))\n","    for j in range(NUM_FALSE_UTT): false_score.append(cosine_similarity(enroll,d_vectors[NUM_ENROLL_UTT+NUM_TRUE_UTT+j]))\n","  \n","  # calculate_eer함수의 인자로 알맞은 형태로 변환. true의 label에 1 표시해주기\n","  scores = np.array(true_score+false_score)\n","  labels = np.array([1.0]*len(true_score)+[0.0]*len(false_score))\n","\n","  # eer 계산\n","  eer,thres = calculate_eer(np.arange(0, 1.0, 0.001), scores, labels, get_threshold=True)\n","  print('EER:', eer)\n","  print('threshold:', thres)\n","\n"," \n","\n","\n","def split_spec(spec):\n","  splited = []\n","  for i in range(0,spec.shape[0]-NUM_FRAME+1,NUM_FRAME//2): splited.append(spec[i:i+NUM_FRAME,:])\n","  return np.array(splited)\n","\n","\n","\n","def eval_one_to_one(model_name, checkpoint_dir, input_dir, N, M):\n","  Model = network.get_network(model_name)\n","\n","  best_ckpt = load_best_checkpoint(checkpoint_dir)\n","  Model.load_weights(checkpoint_dir+'/'+best_ckpt)\n","\n","  #get_thres(Model)\n","\n","\n","  utts_of_speakers = []\n","  for speaker in os.listdir(input_dir):\n","    print(speaker)\n","\n","    for utt in os.listdir(input_dir+'/'+speaker):\n","      print(utt)\n","      spec = convert(input_dir+'/'+speaker+'/'+utt)\n","      utts_of_speakers.append(spec)\n","\n","\n","  d_vectors = []\n","  for utt in utts_of_speakers:\n","    specs = split_spec(utt)\n","    pred = Model.predict(specs)\n","    pred = normalize(pred)\n","    d_vector = normalize(np.mean(pred, axis=0))\n","    d_vectors.append(d_vector)\n","  \n","\n","  simMat = [[int(cosine_similarity(d_vectors[i],d_vectors[j])*100) for i in range(N*M)] for j in range(N*M)]\n","  for i in range(N*M): print(simMat[i])\n","\n","  sim = []\n","  for i in range(N*M):\n","    for j in range(N*M):\n","      sim.append(cosine_similarity(d_vectors[i],d_vectors[j]))\n","  label = []\n","  for i in range(N): label.extend(([0]*(M*i)+[1]*M+[0]*(M*(N-1-i)))*M)\n","\n","  eer,thres = calculate_eer(np.arange(0, 1.0, 0.001), sim, label, get_threshold=True)\n","  print('EER:', eer)\n","  print('threshold:', thres)"],"id":"3dae175d"},{"cell_type":"code","execution_count":null,"metadata":{"id":"jUp8uIlPmTN0"},"outputs":[],"source":["def enroll_test_one_batch(Model, batch, input_dir):\n","  # flatten batch\n","  num_enroll, num_true, num_false = len(batch[0]), len(batch[1]), len(batch[2])\n","  batch = batch[0]+batch[1]+batch[2]\n","\n","  # convert to wav\n","  batch = list(map(lambda x: convert(input_dir+'/'+x), batch))\n","\n","  # convert to d-vector\n","  def wav2vec(wav):\n","    specs = split_spec(wav)\n","    pred = Model.predict(specs)\n","    pred = normalize(pred)\n","    d_vector = normalize(np.mean(pred, axis=0))\n","    return d_vector\n","  batch = np.array(list(map(wav2vec, batch)))\n","\n","  enroll_vecs = batch[:num_enroll]\n","  test_vecs = batch[num_enroll:]\n","\n","  enroll_vec = normalize(np.mean(enroll_vecs, axis=0))\n","  sim_score = np.array(list(map(lambda x:cosine_similarity(enroll_vec,x), test_vecs)))\n","  label = np.array([1]*num_true+[0]*num_false)\n","\n","  return sim_score, label\n","\n","\n","\n","def eval_enroll_test(model_name, checkpoint_dir, input_dir, batch_filenames): # batch = [[[enroll],[true],[false]]] = [[[A_a_1,A_a_2,A_a_3],[B_a_1,B_a_2,B_a_3,C_a_1,C_a_2,C_a_3],[B_b_1,B_b_2,B_b_3,C_b_1,C_b_2,C_b_3, B_c_1,B_c_2,B_c_3,C_c_1,C_c_2,C_c_3]]]\n","  Model = network.get_network(model_name)\n","\n","  best_ckpt = load_best_checkpoint(checkpoint_dir)\n","  Model.load_weights(checkpoint_dir+'/'+best_ckpt)\n","\n","  #get_thres(Model)\n","\n","  sim_scores = []\n","  labels = []\n","  for batch in batch_filenames:\n","    sim_score, label = enroll_test_one_batch(Model, batch, input_dir)\n","    sim_scores.append(sim_score)\n","    labels.append(label)\n","  \n","  # print sim_scores per batch\n","  for i in range(len(sim_scores)):\n","    print()\n","    print('batch:', i)\n","    j = 0\n","    while labels[i][j]: j+=1\n","    print('true utt : ', [int(100*score) for score in sim_scores[i][:j]])\n","    print('false utt : ', [int(100*score) for score in sim_scores[i][j:]])\n","  \n","  # calculate new eer and thres for this batch\n","  eer,thres = calculate_eer(np.arange(0, 1.0, 0.001), np.concatenate(sim_scores), np.concatenate(labels), get_threshold=True)\n","  print('EER:', eer)\n","  print('threshold:', thres)\n","\n","  # 여러개의 enroll-vec으로 각각 score를 구한 뒤, 평균하는 경우를 위한 코드 (case specific temporary code)\n","  print()\n","  print()\n","  print('multiple enrollment vector case')\n","  sim_scores = np.array(sim_scores)\n","  first = np.mean(sim_scores[:3],axis=0)\n","  second = np.mean(sim_scores[3:6],axis=0)\n","  third = np.mean(sim_scores[6:],axis=0)\n","  sim_scores = [first,second,third]\n","  labels = labels[:3]\n","\n","  for i in range(len(sim_scores)):\n","    print()\n","    print('batch:', i)\n","    j = 0\n","    while labels[i][j]: j+=1\n","    print('true utt : ', [int(100*score) for score in sim_scores[i][:j]])\n","    print('false utt : ', [int(100*score) for score in sim_scores[i][j:]])\n","  \n","  # calculate new eer and thres for this batch\n","  eer,thres = calculate_eer(np.arange(0, 1.0, 0.001), np.concatenate(sim_scores), np.concatenate(labels), get_threshold=True)\n","  print('EER:', eer)\n","  print('threshold:', thres)\n"],"id":"jUp8uIlPmTN0"},{"cell_type":"code","execution_count":null,"metadata":{"id":"YCiIQYzKHLnf"},"outputs":[],"source":["from collections import deque\n","\n","def process_audio(model_name, checkpoint_dir,input_dir,enroll_filenames,wav_filename, thres = 0.96):\n","  Model = network.get_network(model_name)\n","  best_ckpt = load_best_checkpoint(checkpoint_dir)\n","  Model.load_weights(checkpoint_dir+'/'+best_ckpt)\n","\n","  # convert to wav\n","  enrolls = list(map(lambda x: convert(input_dir+'/'+x), enroll_filenames))\n","\n","  # convert to d-vector\n","  def wav2vec(wav):\n","    specs = split_spec(wav)\n","    pred = Model.predict(specs)\n","    pred = normalize(pred)\n","    d_vector = normalize(np.mean(pred, axis=0))\n","    return d_vector\n","  enrolls = np.array(list(map(wav2vec, enrolls)))\n","  \n","  # get average d-vector\n","  enroll_vec = normalize(np.mean(enrolls, axis=0))\n","\n","  wav,sr = librosa.load(path=input_dir+'/'+wav_filename)\n","  #wav = wav[:len(wav)//5] # 일단 1분만 사용\n","  wav = librosa.resample(wav, sr, 16000) #downsampling\n","  sr = 16000\n","\n","  hop = int((HOP_LENGTH/16000)*sr)\n","  one_wav_len = hop*128-1\n","\n","  score_Q = deque()\n","  score_sum = 0\n","  max_score_Q_len = 5\n","\n","  detect_Q = deque()\n","  detect_sum = 0\n","  max_detect_Q_len = 10\n","\n","  inf_per_sec = 10\n","  data_per_inf = int(sr/inf_per_sec)\n","\n","  is_detected = False\n","  log = []\n","  last_detected_time = (0,0)\n","\n","  total_inf_num = (len(wav)+1-one_wav_len)//data_per_inf\n","\n","  print('total number of inference:', total_inf_num)\n","  for i in range(one_wav_len,len(wav)+1,data_per_inf):\n","    spec = npy2spec(wav[i-one_wav_len:i],sr) #(128,128,1)\n","    spec = np.expand_dims(spec,axis=0) #(1,128,128,1)\n","\n","    pred = Model.predict(spec)\n","    pred = normalize(pred)[0,:] #(1,200) -> (200)\n","\n","    scores = [cosine_similarity(pred,enroll) for enroll in enrolls]\n","    score = sum(scores)/len(scores)\n","    \n","    score_Q.append(score)\n","    score_sum+=score\n","    if len(score_Q)>max_score_Q_len : score_sum -= score_Q.popleft()\n","    mean_score = score_sum/len(score_Q)\n","\n","    detect = 1 if mean_score>=thres else 0\n","\n","    detect_Q.append(detect)\n","    detect_sum+=detect\n","    if len(detect_Q)>max_detect_Q_len : detect_sum -= detect_Q.popleft()\n","    mean_detect = detect_sum/len(detect_Q)\n","\n","    #print(f'({i/sr:.2f},{score:.2f},{mean_score:.2f},{mean_detect:.2f},{1 if is_detected else 0})', end=' ')\n","\n","    if is_detected==False and mean_detect>=0.6:\n","      is_detected = True\n","      last_detected_time = i-one_wav_len-(len(detect_Q)-1)*data_per_inf\n","    elif is_detected==True and mean_detect<0.6:\n","      is_detected = False\n","      end_time = i-one_wav_len-(len(detect_Q)-1)*data_per_inf\n","      log.append((last_detected_time/sr,end_time/sr))\n","      #print('\\n\\n',last_detected_time/sr,end_time/sr,'\\n')\n","  min_on = 0.5\n","  min_off = 0.5\n","  log_edit = [[0,0]]\n","  for s,e in log:\n","    if s-log_edit[-1][0]<min_off: log_edit[-1][1]=e; continue\n","    if log_edit[-1][1]-log_edit[-1][0]<min_on: log_edit.pop()\n","    log_edit.append([s,e])\n","\n","  for s,e in log_edit:\n","    s*=16000\n","    e*=16000\n","    ipd.display(ipd.Audio(wav[int(s):int(e)], rate = 16000))\n","  \n","  return log_edit"],"id":"YCiIQYzKHLnf"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1uArOli4YwhKoatm7SOMxXANEtULeVFvW"},"executionInfo":{"elapsed":374283,"status":"ok","timestamp":1664445627041,"user":{"displayName":"이중훈","userId":"12039443064831442063"},"user_tz":-540},"id":"Rj9b64Xwgbt5","outputId":"4e87e950-5744-414c-b445-dc8aa5039e99"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["log_edit = process_audio('CRNN','../model/CRNN-simMat_batcher-simMat_loss-931-large', '../data/test2', ['A-1.wav','A-2.wav','A-3.wav'], 'BHandJH3min.wav', 0.96)"],"id":"Rj9b64Xwgbt5"},{"cell_type":"code","execution_count":null,"metadata":{"id":"C3HzXfHCcXKd"},"outputs":[],"source":[],"id":"C3HzXfHCcXKd"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"executionInfo":{"elapsed":38,"status":"ok","timestamp":1664443926548,"user":{"displayName":"이중훈","userId":"12039443064831442063"},"user_tz":-540},"id":"BDZc2ld3zjkq","outputId":"5c4e814a-9e2f-45f9-8aef-f32aad2e67dd"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\nbatch_filename = [[['A-a-1.wav','A-a-2.wav','A-a-3.wav'],['B-a-1.wav','B-a-2.wav','B-a-3.wav','C-a-1.wav','C-a-2.wav','C-a-3.wav'],['B-b-1.wav','B-b-2.wav','B-b-3.wav','C-b-1.wav','C-b-2.wav','C-b-3.wav',  'B-c-1.wav','B-c-2.wav','B-c-3.wav','C-c-1.wav','C-c-2.wav','C-c-3.wav']],\\n                  [['A-b-1.wav','A-b-2.wav','A-b-3.wav'],['B-b-1.wav','B-b-2.wav','B-b-3.wav','C-b-1.wav','C-b-2.wav','C-b-3.wav'],['B-a-1.wav','B-a-2.wav','B-a-3.wav','C-a-1.wav','C-a-2.wav','C-a-3.wav',  'B-c-1.wav','B-c-2.wav','B-c-3.wav','C-c-1.wav','C-c-2.wav','C-c-3.wav']],\\n                  [['A-c-1.wav','A-c-2.wav','A-c-3.wav'],['B-c-1.wav','B-c-2.wav','B-c-3.wav','C-c-1.wav','C-c-2.wav','C-c-3.wav'],['B-b-1.wav','B-b-2.wav','B-b-3.wav','C-b-1.wav','C-b-2.wav','C-b-3.wav',  'B-a-1.wav','B-a-2.wav','B-a-3.wav','C-a-1.wav','C-a-2.wav','C-a-3.wav']]\\n                  ]\\n\\nbatch_filename = [[['A-a-1.wav'],['B-a-1.wav','B-a-2.wav','B-a-3.wav','C-a-1.wav','C-a-2.wav','C-a-3.wav'],['B-b-1.wav','B-b-2.wav','B-b-3.wav','C-b-1.wav','C-b-2.wav','C-b-3.wav',  'B-c-1.wav','B-c-2.wav','B-c-3.wav','C-c-1.wav','C-c-2.wav','C-c-3.wav']],\\n                  [['A-a-2.wav'],['B-a-1.wav','B-a-2.wav','B-a-3.wav','C-a-1.wav','C-a-2.wav','C-a-3.wav'],['B-b-1.wav','B-b-2.wav','B-b-3.wav','C-b-1.wav','C-b-2.wav','C-b-3.wav',  'B-c-1.wav','B-c-2.wav','B-c-3.wav','C-c-1.wav','C-c-2.wav','C-c-3.wav']],\\n                  [['A-a-3.wav'],['B-a-1.wav','B-a-2.wav','B-a-3.wav','C-a-1.wav','C-a-2.wav','C-a-3.wav'],['B-b-1.wav','B-b-2.wav','B-b-3.wav','C-b-1.wav','C-b-2.wav','C-b-3.wav',  'B-c-1.wav','B-c-2.wav','B-c-3.wav','C-c-1.wav','C-c-2.wav','C-c-3.wav']],\\n                  [['A-b-1.wav'],['B-b-1.wav','B-b-2.wav','B-b-3.wav','C-b-1.wav','C-b-2.wav','C-b-3.wav'],['B-a-1.wav','B-a-2.wav','B-a-3.wav','C-a-1.wav','C-a-2.wav','C-a-3.wav',  'B-c-1.wav','B-c-2.wav','B-c-3.wav','C-c-1.wav','C-c-2.wav','C-c-3.wav']],\\n                  [['A-b-2.wav'],['B-b-1.wav','B-b-2.wav','B-b-3.wav','C-b-1.wav','C-b-2.wav','C-b-3.wav'],['B-a-1.wav','B-a-2.wav','B-a-3.wav','C-a-1.wav','C-a-2.wav','C-a-3.wav',  'B-c-1.wav','B-c-2.wav','B-c-3.wav','C-c-1.wav','C-c-2.wav','C-c-3.wav']],\\n                  [['A-b-3.wav'],['B-b-1.wav','B-b-2.wav','B-b-3.wav','C-b-1.wav','C-b-2.wav','C-b-3.wav'],['B-a-1.wav','B-a-2.wav','B-a-3.wav','C-a-1.wav','C-a-2.wav','C-a-3.wav',  'B-c-1.wav','B-c-2.wav','B-c-3.wav','C-c-1.wav','C-c-2.wav','C-c-3.wav']],\\n                  [['A-c-1.wav'],['B-c-1.wav','B-c-2.wav','B-c-3.wav','C-c-1.wav','C-c-2.wav','C-c-3.wav'],['B-b-1.wav','B-b-2.wav','B-b-3.wav','C-b-1.wav','C-b-2.wav','C-b-3.wav',  'B-a-1.wav','B-a-2.wav','B-a-3.wav','C-a-1.wav','C-a-2.wav','C-a-3.wav']],\\n                  [['A-c-2.wav'],['B-c-1.wav','B-c-2.wav','B-c-3.wav','C-c-1.wav','C-c-2.wav','C-c-3.wav'],['B-b-1.wav','B-b-2.wav','B-b-3.wav','C-b-1.wav','C-b-2.wav','C-b-3.wav',  'B-a-1.wav','B-a-2.wav','B-a-3.wav','C-a-1.wav','C-a-2.wav','C-a-3.wav']],\\n                  [['A-c-3.wav'],['B-c-1.wav','B-c-2.wav','B-c-3.wav','C-c-1.wav','C-c-2.wav','C-c-3.wav'],['B-b-1.wav','B-b-2.wav','B-b-3.wav','C-b-1.wav','C-b-2.wav','C-b-3.wav',  'B-a-1.wav','B-a-2.wav','B-a-3.wav','C-a-1.wav','C-a-2.wav','C-a-3.wav']]\\n                  ]\\n\\neval_enroll_test('CRNN','../model/CRNN-simMat_batcher-simMat_loss-931-large', '../data/test_sample', batch_filename)\\n\""]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","batch_filename = [[['A-a-1.wav','A-a-2.wav','A-a-3.wav'],['B-a-1.wav','B-a-2.wav','B-a-3.wav','C-a-1.wav','C-a-2.wav','C-a-3.wav'],['B-b-1.wav','B-b-2.wav','B-b-3.wav','C-b-1.wav','C-b-2.wav','C-b-3.wav',  'B-c-1.wav','B-c-2.wav','B-c-3.wav','C-c-1.wav','C-c-2.wav','C-c-3.wav']],\n","                  [['A-b-1.wav','A-b-2.wav','A-b-3.wav'],['B-b-1.wav','B-b-2.wav','B-b-3.wav','C-b-1.wav','C-b-2.wav','C-b-3.wav'],['B-a-1.wav','B-a-2.wav','B-a-3.wav','C-a-1.wav','C-a-2.wav','C-a-3.wav',  'B-c-1.wav','B-c-2.wav','B-c-3.wav','C-c-1.wav','C-c-2.wav','C-c-3.wav']],\n","                  [['A-c-1.wav','A-c-2.wav','A-c-3.wav'],['B-c-1.wav','B-c-2.wav','B-c-3.wav','C-c-1.wav','C-c-2.wav','C-c-3.wav'],['B-b-1.wav','B-b-2.wav','B-b-3.wav','C-b-1.wav','C-b-2.wav','C-b-3.wav',  'B-a-1.wav','B-a-2.wav','B-a-3.wav','C-a-1.wav','C-a-2.wav','C-a-3.wav']]\n","                  ]\n","\n","batch_filename = [[['A-a-1.wav'],['B-a-1.wav','B-a-2.wav','B-a-3.wav','C-a-1.wav','C-a-2.wav','C-a-3.wav'],['B-b-1.wav','B-b-2.wav','B-b-3.wav','C-b-1.wav','C-b-2.wav','C-b-3.wav',  'B-c-1.wav','B-c-2.wav','B-c-3.wav','C-c-1.wav','C-c-2.wav','C-c-3.wav']],\n","                  [['A-a-2.wav'],['B-a-1.wav','B-a-2.wav','B-a-3.wav','C-a-1.wav','C-a-2.wav','C-a-3.wav'],['B-b-1.wav','B-b-2.wav','B-b-3.wav','C-b-1.wav','C-b-2.wav','C-b-3.wav',  'B-c-1.wav','B-c-2.wav','B-c-3.wav','C-c-1.wav','C-c-2.wav','C-c-3.wav']],\n","                  [['A-a-3.wav'],['B-a-1.wav','B-a-2.wav','B-a-3.wav','C-a-1.wav','C-a-2.wav','C-a-3.wav'],['B-b-1.wav','B-b-2.wav','B-b-3.wav','C-b-1.wav','C-b-2.wav','C-b-3.wav',  'B-c-1.wav','B-c-2.wav','B-c-3.wav','C-c-1.wav','C-c-2.wav','C-c-3.wav']],\n","                  [['A-b-1.wav'],['B-b-1.wav','B-b-2.wav','B-b-3.wav','C-b-1.wav','C-b-2.wav','C-b-3.wav'],['B-a-1.wav','B-a-2.wav','B-a-3.wav','C-a-1.wav','C-a-2.wav','C-a-3.wav',  'B-c-1.wav','B-c-2.wav','B-c-3.wav','C-c-1.wav','C-c-2.wav','C-c-3.wav']],\n","                  [['A-b-2.wav'],['B-b-1.wav','B-b-2.wav','B-b-3.wav','C-b-1.wav','C-b-2.wav','C-b-3.wav'],['B-a-1.wav','B-a-2.wav','B-a-3.wav','C-a-1.wav','C-a-2.wav','C-a-3.wav',  'B-c-1.wav','B-c-2.wav','B-c-3.wav','C-c-1.wav','C-c-2.wav','C-c-3.wav']],\n","                  [['A-b-3.wav'],['B-b-1.wav','B-b-2.wav','B-b-3.wav','C-b-1.wav','C-b-2.wav','C-b-3.wav'],['B-a-1.wav','B-a-2.wav','B-a-3.wav','C-a-1.wav','C-a-2.wav','C-a-3.wav',  'B-c-1.wav','B-c-2.wav','B-c-3.wav','C-c-1.wav','C-c-2.wav','C-c-3.wav']],\n","                  [['A-c-1.wav'],['B-c-1.wav','B-c-2.wav','B-c-3.wav','C-c-1.wav','C-c-2.wav','C-c-3.wav'],['B-b-1.wav','B-b-2.wav','B-b-3.wav','C-b-1.wav','C-b-2.wav','C-b-3.wav',  'B-a-1.wav','B-a-2.wav','B-a-3.wav','C-a-1.wav','C-a-2.wav','C-a-3.wav']],\n","                  [['A-c-2.wav'],['B-c-1.wav','B-c-2.wav','B-c-3.wav','C-c-1.wav','C-c-2.wav','C-c-3.wav'],['B-b-1.wav','B-b-2.wav','B-b-3.wav','C-b-1.wav','C-b-2.wav','C-b-3.wav',  'B-a-1.wav','B-a-2.wav','B-a-3.wav','C-a-1.wav','C-a-2.wav','C-a-3.wav']],\n","                  [['A-c-3.wav'],['B-c-1.wav','B-c-2.wav','B-c-3.wav','C-c-1.wav','C-c-2.wav','C-c-3.wav'],['B-b-1.wav','B-b-2.wav','B-b-3.wav','C-b-1.wav','C-b-2.wav','C-b-3.wav',  'B-a-1.wav','B-a-2.wav','B-a-3.wav','C-a-1.wav','C-a-2.wav','C-a-3.wav']]\n","                  ]\n","\n","eval_enroll_test('CRNN','../model/CRNN-simMat_batcher-simMat_loss-931-large', '../data/test_sample', batch_filename)\n","\"\"\""],"id":"BDZc2ld3zjkq"},{"cell_type":"code","execution_count":null,"metadata":{"id":"e6e6591d","scrolled":true},"outputs":[],"source":["#eva_one_to_onel('CRNN','../model/CRNN-simMat_batcher-simMat_loss-931-large', '../data/sample', N=6, M=5)"],"id":"e6e6591d"}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":5}