{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arjasc5231/Lingometer/blob/speaker_verification/speaker_verification/batcher.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2ebe9f4",
      "metadata": {
        "id": "a2ebe9f4"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arjasc5231/Lingometer/blob/speaker_verification/speaker_verificaiton/batcher.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4419aa6f",
      "metadata": {
        "id": "4419aa6f",
        "outputId": "011bdbb2-3da8-43b7-e468-92f9bc59502b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "importing Jupyter notebook from constants.ipynb\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "\n",
        "import import_ipynb\n",
        "from constants import NUM_FBANK, HOP_LENGTH, NUM_PER_SPEAKER, NUM_FRAME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58220255",
      "metadata": {
        "id": "58220255",
        "outputId": "bf1a538e-2f49-4257-9fe5-abd967f4a708"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'NUM_FRAME' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mnaive_batcher\u001b[39;00m:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_dir, output_dir):\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnaive_batcher\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
            "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36mnaive_batcher\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dir)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_speaker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m])\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_frame\u001b[38;5;241m=\u001b[39m\u001b[43mNUM_FRAME\u001b[49m, num_per_speaker\u001b[38;5;241m=\u001b[39mNUM_PER_SPEAKER):\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m#if len(os.listdir(self.output_dir))!=0: error()\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     X \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     15\u001b[0m     Y \u001b[38;5;241m=\u001b[39m []\n",
            "\u001b[1;31mNameError\u001b[0m: name 'NUM_FRAME' is not defined"
          ]
        }
      ],
      "source": [
        "class naive_batcher:\n",
        "    def __init__(self, input_dir, output_dir):\n",
        "        self.name = 'naive_batcher'\n",
        "        self.input_dir = input_dir\n",
        "        self.output_dir = output_dir\n",
        "        \n",
        "        if len(os.listdir(self.output_dir))==0: self.generate()\n",
        "        else: print('load exist data')\n",
        "        self.filename = os.listdir(self.output_dir)[0]\n",
        "        self.num_speaker = int(self.filename.split('_')[-4])\n",
        "    \n",
        "    def generate(self, num_frame=NUM_FRAME, num_per_speaker=NUM_PER_SPEAKER):\n",
        "        #if len(os.listdir(self.output_dir))!=0: error()\n",
        "        X = []\n",
        "        Y = []\n",
        "        speaker_id = 0        \n",
        "        \n",
        "        for speaker in os.listdir(self.input_dir):\n",
        "            X_speaker = []\n",
        "            for utt in os.listdir(self.input_dir+'/'+speaker):\n",
        "                spec = np.load(self.input_dir+'/'+speaker+'/'+utt)\n",
        "                for i in range(0,spec.shape[0]-num_frame+1,num_frame): X_speaker.append(spec[i:i+num_frame,:])\n",
        "                if len(X_speaker)>=num_per_speaker: break\n",
        "            if len(X_speaker)<num_per_speaker: continue\n",
        "            X.extend(X_speaker[:num_per_speaker])\n",
        "            Y.extend([speaker_id]*num_per_speaker)\n",
        "            speaker_id+=1\n",
        "        X = np.array(X)\n",
        "        Y = np.array(Y)\n",
        "        \n",
        "        # shuffle utterances\n",
        "        shuffle_idx = np.arange(X.shape[0])\n",
        "        np.random.shuffle(shuffle_idx)\n",
        "        X = X[shuffle_idx]\n",
        "        Y = Y[shuffle_idx]\n",
        "        \n",
        "        # split train/test\n",
        "        split_idx = int(X.shape[0]*0.8)\n",
        "        X_train, X_test, Y_train, Y_test = X[:split_idx], X[split_idx:], Y[:split_idx], Y[split_idx:]\n",
        "        \n",
        "        # print information\n",
        "        print()\n",
        "        print('generate train/test dataset')\n",
        "        print('shape:', X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
        "        \n",
        "        # save\n",
        "        XY = (X_train, X_test, Y_train, Y_test)\n",
        "        with open(self.output_dir+'/'+f\"{speaker_id}_{NUM_PER_SPEAKER}_{NUM_FRAME}_{NUM_FBANK}.npy\",'wb') as f:\n",
        "            pickle.dump(XY,f)\n",
        "        \n",
        "    def load_data(self):\n",
        "        with open(self.output_dir+'/'+self.filename,\"rb\") as f:\n",
        "            return pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "704bc7e5",
      "metadata": {
        "id": "704bc7e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "ff0280fd-7cb4-43c9-b1cf-1b3bdcd824bd"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-55b2a852f920>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0msimMat_batcher\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;31m# 원래 논문(코드)에서는 batch의 크기를 고정하고 대신 batch마다 시간축의 길이를 유동적으로 변할 수 있게 모델링했다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# 하지만 그렇게 하려면 모델의 구조를 바꿔야 하는걸... 시간 다르게는 나중에 구현하기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'simMat_batcher'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-55b2a852f920>\u001b[0m in \u001b[0;36msimMat_batcher\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m#             10000으로 설정하면 Unable to allocate 15.3 GiB for an array with shape (10000, 25, 128, 128, 1) and data type float32에러 뜨는데?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# 미리 모든 데이터를 생성해 두는 것이 메모리가 부족하다면 화자별로 스펙트로그램을 300개씩 뽑은 것을 드라이브에 올리고, 실시간으로 배치 하나씩 생성하는 방법이 있겠다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_FRAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_speaker_per_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_utt_per_speaker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mspecs_of_speaker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'NUM_FRAME' is not defined"
          ]
        }
      ],
      "source": [
        "class simMat_batcher:\n",
        "    # 원래 논문(코드)에서는 batch의 크기를 고정하고 대신 batch마다 시간축의 길이를 유동적으로 변할 수 있게 모델링했다.\n",
        "    # 하지만 그렇게 하려면 모델의 구조를 바꿔야 하는걸... 시간 다르게는 나중에 구현하기\n",
        "    def __init__(self, input_dir, output_dir):\n",
        "        self.name = 'simMat_batcher'\n",
        "        self.input_dir = input_dir\n",
        "        self.output_dir = output_dir\n",
        "        \n",
        "        if len(os.listdir(self.output_dir))==0: self.generate()\n",
        "        else: print('load exist data')\n",
        "        self.filename = os.listdir(self.output_dir)[0]\n",
        "        self.num_speaker = int(self.filename.split('_')[0]) # num_speaker는 이 batcher에서 의미없다. 일단 모델을 만들기 위해 설정\n",
        "    \n",
        "    # num_speaker_per_batch : 배치당 화자 수. 논문=64 코드=4. 일단은 5개 발화로 등록한다 가정하고 5로 설정.\n",
        "    # num_utt_per_speaker : 배치당 화자마다 발화 수. 논문=10 코드=5\n",
        "    # num_batch : 총 몇개의 배치(사실상 에폭)을 학습시킬 것인가. 코드=100000. 일단은 테스트만 해보려고 작게 1000으로 설정.\n",
        "    def generate(self, num_frame=NUM_FRAME, num_speaker_per_batch=5, num_utt_per_speaker=5, num_batch=1000):\n",
        "        \n",
        "        specs_of_speaker = []\n",
        "        for speaker in os.listdir(self.input_dir):\n",
        "            X_speaker = []\n",
        "            for utt in os.listdir(self.input_dir+'/'+speaker):\n",
        "                spec = np.load(self.input_dir+'/'+speaker+'/'+utt)\n",
        "                for i in range(0,spec.shape[0]-NUM_FRAME+1,NUM_FRAME): X_speaker.append(spec[i:i+NUM_FRAME,:])\n",
        "                if len(X_speaker)>=NUM_PER_SPEAKER: break\n",
        "            if len(X_speaker)<NUM_PER_SPEAKER: continue\n",
        "            specs_of_speaker.append(np.array(X_speaker[:NUM_PER_SPEAKER]))\n",
        "        specs_of_speaker = np.array(specs_of_speaker)\n",
        "        num_speaker = len(specs_of_speaker)\n",
        "        print('number of speakers who has more than minimun:', num_speaker)\n",
        "\n",
        "        # sample utterances for train\n",
        "        X = []\n",
        "        for i in range(num_batch):\n",
        "            batch = []\n",
        "            speakers = np.random.choice(num_speaker, num_speaker_per_batch, replace=False)\n",
        "            for speaker in speakers:\n",
        "                utts_idx = np.random.choice(NUM_PER_SPEAKER, num_utt_per_speaker, replace=False)\n",
        "                batch.append(specs_of_speaker[speaker][utts_idx])\n",
        "            batch = np.concatenate(batch)\n",
        "            X.append(batch)\n",
        "        X = np.array(X)\n",
        "        print('total generated shape:',X.shape)\n",
        "\n",
        "        Y = np.zeros(X.shape[:2]) # dummy\n",
        "        print('dummy Y shape:',Y.shape)\n",
        "\n",
        "        # save\n",
        "        XY = (X, Y)\n",
        "        with open(self.output_dir+'/'+f\"{num_speaker}_{NUM_PER_SPEAKER}_{NUM_FRAME}_{NUM_FBANK}_{num_speaker_per_batch}_{num_utt_per_speaker}_{num_batch}.npy\",'wb') as f:\n",
        "            pickle.dump(XY,f)\n",
        "        \n",
        "    def load_data(self):\n",
        "        with open(self.output_dir+'/'+self.filename,\"rb\") as f:\n",
        "            return pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class simMat_online_batcher:\n",
        "    # 원래 논문(코드)에서는 batch의 크기를 고정하고 대신 batch마다 시간축의 길이를 유동적으로 변할 수 있게 모델링했다.\n",
        "    # 하지만 그렇게 하려면 모델의 구조를 바꿔야 하는걸... 시간 다르게는 나중에 구현하기\n",
        "    def __init__(self, input_dir, output_dir):\n",
        "        self.name = 'simMat_online_batcher'\n",
        "        self.input_dir = input_dir\n",
        "        self.output_dir = output_dir\n",
        "        \n",
        "        # load data\n",
        "        if len(os.listdir(self.output_dir))==0: self.generate()\n",
        "        else: print('load exist data')\n",
        "        self.filename = os.listdir(self.output_dir)[0]\n",
        "        self.num_speaker = int(self.filename.split('_')[1]) # num_speaker는 이 batcher에서 의미없다. 일단 모델을 만들기 위해 설정\n",
        "        self.specs_of_speakers = self.load_data()\n",
        "    \n",
        "\n",
        "    # simMat batcher를 online으로 하기 위해 각 화자마다 스펙트로그램 300개씩 뽑아 업로드\n",
        "    # 사실상 naive_batcher가 만든 데이터 npy파일이 화자별로 정렬되어있는 것 뿐이다.\n",
        "    def generate(self, num_frame=NUM_FRAME):\n",
        "\n",
        "        specs_of_speaker = []\n",
        "        for speaker in os.listdir(input_dir):\n",
        "            X_speaker = []\n",
        "            for utt in os.listdir(input_dir+'/'+speaker):\n",
        "                spec = np.load(input_dir+'/'+speaker+'/'+utt)\n",
        "                for i in range(0,spec.shape[0]-NUM_FRAME+1,NUM_FRAME): X_speaker.append(spec[i:i+NUM_FRAME,:])\n",
        "                if len(X_speaker)>=NUM_PER_SPEAKER: break\n",
        "            if len(X_speaker)<NUM_PER_SPEAKER: continue\n",
        "            specs_of_speaker.append(np.array(X_speaker[:NUM_PER_SPEAKER]))\n",
        "        specs_of_speaker = np.array(specs_of_speaker)\n",
        "        num_speaker = len(specs_of_speaker)\n",
        "        print('shape:', specs_of_speaker.shape)\n",
        "\n",
        "        # save\n",
        "        with open(output_dir+'/'+f\"specsOfSpeakers_{num_speaker}_{NUM_PER_SPEAKER}_{NUM_FRAME}_{NUM_FBANK}.npy\",'wb') as f:\n",
        "            pickle.dump(specs_of_speaker,f)\n",
        "\n",
        "    \n",
        "\n",
        "    # num_speaker_per_batch : 배치당 화자 수. 논문=64 코드=4. 일단은 5개 발화로 등록한다 가정하고 5로 설정.\n",
        "    # num_utt_per_speaker : 배치당 화자마다 발화 수. 논문=10 코드=5\n",
        "    def get_batch(self, num_speaker_per_batch=5, num_utt_per_speaker=5):\n",
        "\n",
        "        batch = []\n",
        "        speakers = np.random.choice(self.num_speaker, num_speaker_per_batch, replace=False)\n",
        "        for speaker in speakers:\n",
        "            utts_idx = np.random.choice(NUM_PER_SPEAKER, num_utt_per_speaker, replace=False)\n",
        "            batch.append(self.specs_of_speakers[speaker][utts_idx])\n",
        "        batch = np.concatenate(batch)\n",
        "\n",
        "        Y = np.zeros(batch.shape[0]) # dummy\n",
        "\n",
        "        return batch,Y\n",
        "    \n",
        "    def train_generator(self):\n",
        "        while True:\n",
        "            yield self.get_batch()\n",
        "        \n",
        "    def load_data(self):\n",
        "        with open(self.output_dir+'/'+self.filename,\"rb\") as f:\n",
        "            return pickle.load(f)"
      ],
      "metadata": {
        "id": "f1r8mXZTIgdy"
      },
      "id": "f1r8mXZTIgdy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25305ca6",
      "metadata": {
        "id": "25305ca6"
      },
      "outputs": [],
      "source": [
        "def get_batcher(batcher_name, input_dir, output_dir):\n",
        "    if batcher_name=='naive_batcher': return naive_batcher(input_dir, output_dir)\n",
        "    elif batcher_name=='simMat_batcher': return simMat_batcher(input_dir, output_dir)\n",
        "    elif batcher_name=='simMat_online_batcher': return simMat_online_batcher(input_dir, output_dir)\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1895581",
      "metadata": {
        "id": "b1895581"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb4d3833",
      "metadata": {
        "id": "cb4d3833"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cb7d8ee",
      "metadata": {
        "id": "3cb7d8ee",
        "outputId": "bcff57f4-232b-4164-e1dc-27df114a190e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of speakers who has more than minimun: 167\n",
            "total generated shape: (1000, 25, 128, 128, 1)\n",
            "dummy Y shape: (1000, 25)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<__main__.simMat_batcher at 0x1adc5592520>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#simMat_batcher('C:/Users/LeeJunghun/Desktop/lingometer/data/NIKL_DIALOGUE_2020_PCM_v1.2_part1/NIKL_DIALOGUE_2020_PCM_v1.2_part1/npy/traintest','C:/Users/LeeJunghun/Desktop/lingometer/data/NIKL_DIALOGUE_2020_PCM_v1.2_part1/NIKL_DIALOGUE_2020_PCM_v1.2_part1/simMat_batcher')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "batcher.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}