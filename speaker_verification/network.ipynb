{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arjasc5231/Lingometer/blob/speaker_verification/speaker_verification/network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a898857f",
      "metadata": {
        "id": "a898857f"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from eval_metrics import calculate_eer\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomModel(keras.Model):\n",
        "    def test_step(self, data):\n",
        "        # Unpack the data. y data 사용 안함\n",
        "        x, _ = data \n",
        "\n",
        "        \"\"\"\n",
        "        이하 validate의 코드를 복붙한 것이기 때문에 어색한 것이 있을 수 있음\n",
        "        * num_batch같은 건 차라리 X에서 20개 단위로 끊어지도록 할 수 있겠다.\n",
        "        * 화자수, 발화 수도 compile같은 단계에서 유동적으로 넣어줄 수 있겠다.\n",
        "        \"\"\"\n",
        "        num_batch = x.shape[0]//20  # 한번의 테스트에 20개의 발화가 있을 때, 테스트의 개수 구하기\n",
        "        true_score = []   # true 발화의 점수를 저장할 배열\n",
        "        false_score = []  # false 발화의 점수를 저장할 배열\n",
        "\n",
        "\n",
        "        def cosine_similarity(a,b):\n",
        "          def dot(A,B): return (sum(a*b for a,b in zip(A,B)))\n",
        "          return dot(a,b)/((dot(a,a)**0.5)*(dot(b,b)**0.5))\n",
        "\n",
        "        # 한번의 테스트에 5/5/10으로 구성되어있다 할 때 점수 계산하기\n",
        "        for i in range(num_batch):\n",
        "          y_pred = self(x[i*20:i*20+20], training=False).numpy()\n",
        "\n",
        "          enroll = y_pred[:5]\n",
        "          enroll = np.mean(enroll, axis=0) # 등록 발화 5개를 평균.             ########### 여기만 tf.reduce_average로 바꾸면 되지 않을까.\n",
        "\n",
        "          for j in range(5): true_score.append(cosine_similarity(enroll,y_pred[5+j]))\n",
        "          for j in range(10): false_score.append(cosine_similarity(enroll,y_pred[10+j]))\n",
        "\n",
        "        # calculate_eer함수의 인자로 알맞은 형태로 변환. true의 label에 1 표시해주기\n",
        "        scores = np.array(true_score+false_score)\n",
        "        labels = np.array([1.0]*len(true_score)+[0.0]*len(false_score))\n",
        "\n",
        "        # eer 계산\n",
        "        eer = calculate_eer(np.arange(0, 1.0, 0.001), scores, labels)\n",
        "        return {\"eer\": eer}"
      ],
      "metadata": {
        "id": "OxBIReTDLk_b"
      },
      "id": "OxBIReTDLk_b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "548786c7",
      "metadata": {
        "id": "548786c7"
      },
      "outputs": [],
      "source": [
        "def naive_model(num_speaker):\n",
        "    inputs = keras.Input(shape=(128, 128, 1))\n",
        "    conv1 = keras.layers.Conv2D(filters=32, kernel_size=[3, 3], activation=tf.nn.relu)(inputs)\n",
        "    pool1 = keras.layers.MaxPool2D(padding='SAME')(conv1)\n",
        "    conv2 = keras.layers.Conv2D(filters=64, kernel_size=[3, 3], activation=tf.nn.relu)(pool1)\n",
        "    pool2 = keras.layers.MaxPool2D(padding='SAME')(conv2)\n",
        "    conv3 = keras.layers.Conv2D(filters=128, kernel_size=[3, 3], activation=tf.nn.relu)(pool2)\n",
        "    pool3 = keras.layers.MaxPool2D(padding='SAME')(conv3)\n",
        "    \n",
        "    \"\"\"\n",
        "    trans = keras.layers.Permute((2,1,3))(pool3)\n",
        "    reshape = keras.layers.Reshape((-1, 15*128))(trans) # 열 개수(freq축)*ch\n",
        "    lstm = keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True, dropout=0.3))(reshape) # (time=15,hidden=256)\n",
        "\n",
        "    attention_score1 = keras.layers.Dense(1, activation='tanh')(lstm) # lstm(time,hidden)*W(hidden,1)=score(time,1)\n",
        "    attention_score2 = keras.layers.Softmax()(attention_score1)\n",
        "    attention = keras.layers.Dot(axes=(1,1))([lstm, attention_score2]) # (time=15, hidden=256) * (time,) => (hidden=256)\n",
        "    flatten = keras.layers.Flatten()(attention)\n",
        "    \"\"\"\n",
        "    \n",
        "    flatten = keras.layers.Flatten()(pool3)\n",
        "    fc = keras.layers.Dense(num_speaker)(flatten)\n",
        "    return CustomModel(inputs=inputs, outputs=fc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b3811c0",
      "metadata": {
        "id": "6b3811c0"
      },
      "outputs": [],
      "source": [
        "def get_network(model_name, num_speaker):\n",
        "    if model_name=='naive_model': return naive_model(num_speaker)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9d19fe1",
      "metadata": {
        "id": "c9d19fe1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "name": "network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}