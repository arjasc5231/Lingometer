{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arjasc5231/Lingometer/blob/speaker_verification/speaker_verification/loss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4da1e179",
      "metadata": {
        "id": "4da1e179"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "keras에서 custom loss 만드는 법 아래 블로그 참고\n",
        "https://blog.naver.com/PostView.nhn?blogId=siniphia&logNo=221972407157\n",
        "\"\"\"\n",
        "def normalize(x):\n",
        "    return x/tf.sqrt(tf.reduce_sum(x**2, axis=-1, keepdims=True)+1e-6)\n",
        "\n",
        "\n",
        "def simMat_loss(y_true, y_pred):\n",
        "  N = 5  # 화자 수\n",
        "  M = 5  # 화자당 발화 수\n",
        "\n",
        "  embedded_split = tf.reshape(normalize(y_pred), shape=[N, M, -1])\n",
        "\n",
        "  center = normalize(tf.reduce_mean(embedded_split, axis=1))  # 화자마다 모든 발화의 평균. [N][P]\n",
        "  center_except = normalize(tf.reshape(tf.reduce_sum(embedded_split, axis=1, keepdims=True)- embedded_split, shape=[N*M,-1]))  # 각 발화에 대해, 그 발화를 제외한 화자 내의 평균. [N][M][P]\n",
        "  \n",
        "  S = tf.concat(\n",
        "      [tf.concat([tf.reduce_sum(center_except[i*M:(i+1)*M,:]*embedded_split[j,:,:], axis=1, keepdims=True) if i==j\n",
        "                  else tf.reduce_sum(center[i:(i+1),:]*embedded_split[j,:,:], axis=1, keepdims=True) for i in range(N)],\n",
        "                  axis=1) for j in range(N)], axis=0)\n",
        "\n",
        "  S_correct = tf.concat([S[i*M:(i+1)*M, i:(i+1)] for i in range(N)], axis=0)\n",
        "  total = -tf.reduce_sum(S_correct-tf.math.log(tf.reduce_sum(tf.exp(S), axis=1, keepdims=True) + 1e-6))\n",
        "  \n",
        "  \"\"\"\n",
        "  loss를 batch별로 확인하고 싶다면 주석을 풀고 아래 코드를 사용하는데,\n",
        "  print(total.numpy())\n",
        "  tensor.numpy()로 실시간으로 tensor의 값을 확인하려면 아래 코드를 처음에 추가해줘야 한다.\n",
        "  tf.config.run_functions_eagerly(True)\n",
        "  \"\"\"\n",
        "\n",
        "  return total\n",
        "  # cosine sim을 parametric하게 하는건 아직 구현 안함"
      ],
      "metadata": {
        "id": "uBU76rveRlW-"
      },
      "id": "uBU76rveRlW-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "393c1d7b",
      "metadata": {
        "id": "393c1d7b"
      },
      "outputs": [],
      "source": [
        "def get_loss(loss_name):\n",
        "    if loss_name=='cross_entropy': return keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    elif loss_name=='simMat_loss': return simMat_loss"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "name": "loss.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}